@book{allenHaskellProgrammingFirst2016,
  title = {Haskell {{Programming}} from {{First Principles}}},
  author = {Allen, C. and Moronuki, J. and Syrek, S.},
  year = {2016},
  publisher = {{Lorepub LLC}},
  isbn = {978-1-945388-03-3},
  file = {/home/lazylambda/Zotero/storage/JVV2AAKH/Haskell Programming.pdf}
}

@book{aroraComputationalComplexityModern2009,
  title = {Computational {{Complexity}}: {{A Modern Approach}}},
  shorttitle = {Computational {{Complexity}}},
  author = {Arora, Sanjeev and Barak, Boaz},
  year = {2009},
  month = apr,
  edition = {1},
  publisher = {{Cambridge University Press}},
  doi = {10.1017/CBO9780511804090},
  urldate = {2023-08-19},
  abstract = {This beginning graduate textbook describes both recent achievements and classical results of computational complexity theory. Requiring essentially no background apart from mathematical maturity, the book can be used as a reference for self-study for anyone interested in complexity, including physicists, mathematicians, and other scientists, as well as a textbook for a variety of courses and seminars. More than 300 exercises are included with a selected hint set. The book starts with a broad introduction to the field and progresses to advanced results. Contents include: definition of Turing machines and basic time and space complexity classes, probabilistic algorithms, interactive proofs, cryptography, quantum computation, lower bounds for concrete computational models (decision trees, communication complexity, constant depth, algebraic and monotone circuits, proof complexity), average-case complexity and hardness amplification, derandomization and pseudorandom constructions, and the PCP theorem.},
  isbn = {978-0-521-42426-4 978-0-511-80409-0},
  langid = {english},
  file = {/home/lazylambda/Zotero/storage/A42XWNK6/Arora and Barak - 2009 - Computational Complexity A Modern Approach.pdf}
}

@misc{HaskellLanguage,
  title = {Haskell {{Language}}},
  urldate = {2023-08-19},
  howpublished = {https://www.haskell.org/},
  file = {/home/lazylambda/Zotero/storage/ZQV3UZM3/www.haskell.org.html}
}

@article{hoffmannTwoDecadesAutomatic2022,
  title = {Two Decades of Automatic Amortized Resource Analysis},
  author = {Hoffmann, Jan and Jost, Steffen},
  year = {2022},
  month = jun,
  journal = {Mathematical Structures in Computer Science},
  volume = {32},
  number = {6},
  pages = {729--759},
  issn = {0960-1295, 1469-8072},
  doi = {10.1017/S0960129521000487},
  urldate = {2023-05-23},
  abstract = {This article gives an overview of automatic amortized resource analysis (AARA), a technique for inferring symbolic resource bounds for programs at compile time. AARA has been introduced by Hofmann and Jost in 2003 as a type system for deriving linear worst-case bounds on the heap-space consumption of first-order functional programs with eager evaluation strategy. Since then AARA has been the subject of dozens of research articles, which extended the analysis to different resource metrics, other evaluation strategies, non-linear bounds, and additional language features. All these works preserved the defining characteristics of the original paper: local inference rules, which reduce bound inference to numeric (usually linear) optimization; a soundness proof with respect to an operational cost semantics; and the support of amortized analysis with the potential method.},
  langid = {english},
  file = {/home/lazylambda/Zotero/storage/JV3SJR9J/Hoffmann and Jost - 2022 - Two decades of automatic amortized resource analys.pdf}
}

@book{hoffmannTypesPotentialPolynomial2011,
  title = {Types with Potential: Polynomial Resource Bounds via Automatic Amortized Analysis},
  shorttitle = {Types with Potential},
  author = {Hoffmann, Jan},
  year = {2011},
  publisher = {{epubli-Verl}},
  address = {{Berlin}},
  isbn = {978-3-8442-1516-8},
  langid = {english},
  file = {/home/lazylambda/Zotero/storage/EHEHAPPL/Hoffmann - 2011 - Types with potential polynomial resource bounds v.pdf}
}

@article{LinearProgramming2023,
  title = {Linear Programming},
  year = {2023},
  month = aug,
  journal = {Wikipedia},
  urldate = {2023-08-19},
  abstract = {Linear programming (LP), also called linear optimization, is a method to achieve the best outcome (such as maximum profit or lowest cost) in a mathematical model whose requirements are represented by linear relationships. Linear programming is a special case of mathematical programming (also known as mathematical optimization). More formally, linear programming is a technique for the optimization of a linear objective function, subject to linear equality and linear inequality constraints. Its feasible region is a convex polytope, which is a set defined as the intersection of finitely many half spaces, each of which is defined by a linear inequality. Its objective function is a real-valued affine (linear) function defined on this polyhedron. A linear programming algorithm finds a point in the polytope where this function has the smallest (or largest) value if such a point exists. Linear programs are problems that can be expressed in canonical form as                                                                                                                  Find a vector                                                                                                  x                                                                                                                            that maximizes                                                                                                                       c                                                                                  T                                                                                             x                                                                                                                            subject to                                                                               A                                    x                                  {$\leq$}                                    b                                                                                                                            and                                                                                                  x                                  {$\geq$}                                    0                                  .                                                                 \{\textbackslash displaystyle \{\textbackslash begin\{aligned\}\&\{\textbackslash text\{Find a vector\}\}\&\&\textbackslash mathbf \{x\} \textbackslash\textbackslash\&\{\textbackslash text\{that maximizes\}\}\&\&\textbackslash mathbf \{c\} \^\{\textbackslash mathsf \{T\}\}\textbackslash mathbf \{x\} \textbackslash\textbackslash\&\{\textbackslash text\{subject to\}\}\&\&A\textbackslash mathbf \{x\} \textbackslash leq \textbackslash mathbf \{b\} \textbackslash\textbackslash\&\{\textbackslash text\{and\}\}\&\&\textbackslash mathbf \{x\} \textbackslash geq \textbackslash mathbf \{0\} .\textbackslash end\{aligned\}\}\}   Here the components of x are the variables to be determined, c and b are given vectors (with                                                 c                                                  T                                                  \{\textbackslash displaystyle \textbackslash mathbf \{c\} \^\{\textbackslash mathsf \{T\}\}\}    indicating that the coefficients of c are used as a single-row matrix for the purpose of forming the matrix product), and A is a given matrix. The function whose value is to be maximized or minimized (                                   x                  {$\mapsto$}                                 c                                                  T                                                     x                          \{\textbackslash displaystyle \textbackslash mathbf \{x\} \textbackslash mapsto \textbackslash mathbf \{c\} \^\{\textbackslash mathsf \{T\}\}\textbackslash mathbf \{x\} \}    in this case) is called the objective function. The inequalities Ax {$\leq$} b and x {$\geq$} 0 are the constraints which specify a convex polytope over which the objective function is to be optimized. In this context, two vectors are comparable when they have the same dimensions. If every entry in the first is less-than or equal-to the corresponding entry in the second, then it can be said that the first vector is less-than or equal-to the second vector. Linear programming can be applied to various fields of study. It is widely used in mathematics and, to a lesser extent, in business, economics, and some engineering problems. Industries that use linear programming models include transportation, energy, telecommunications, and manufacturing. It has proven useful in modeling diverse types of problems in planning, routing, scheduling, assignment, and design.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1169676293},
  file = {/home/lazylambda/Zotero/storage/77QYJRVR/Linear_programming.html}
}

@book{nederpeltTypeTheoryFormal2014,
  title = {Type {{Theory}} and {{Formal Proof}}: {{An Introduction}}},
  author = {Nederpelt, Rob and Geuvers, Herman},
  year = {2014},
  publisher = {{Cambridge University Press}},
  address = {{Cambridge}},
  doi = {10.1017/CBO9781139567725},
  abstract = {Type theory is a fast-evolving field at the crossroads of logic, computer science and mathematics. This gentle step-by-step introduction is ideal for graduate students and researchers who need to understand the ins and outs of the mathematical machinery, the role of logical rules therein, the essential contribution of definitions and the decisive nature of well-structured proofs. The authors begin with untyped lambda calculus and proceed to several fundamental type systems, including the well-known and powerful Calculus of Constructions. The book also covers the essence of proof checking and proof development, and the use of dependent type theory to formalise mathematics. The only prerequisite is a basic knowledge of undergraduate mathematics. Carefully chosen examples illustrate the theory throughout. Each chapter ends with a summary of the content, some historical context, suggestions for further reading and a selection of exercises to help readers familiarise themselves with the material.},
  isbn = {978-1-107-03650-5},
  file = {/home/lazylambda/Zotero/storage/4BCNSTVX/Definitions.pdf;/home/lazylambda/Zotero/storage/4Z9GYTPZ/Numbers and arithmetic in D.pdf;/home/lazylambda/Zotero/storage/888FMSZB/Further perspectives.pdf;/home/lazylambda/Zotero/storage/9CJKJTV3/Extension of C with definitions.pdf;/home/lazylambda/Zotero/storage/B7N3CEXW/Types dependent on terms.pdf;/home/lazylambda/Zotero/storage/HPQVK9GG/Simply typed lambda calculus.pdf;/home/lazylambda/Zotero/storage/J2JWRG7C/Types dependent on types.pdf;/home/lazylambda/Zotero/storage/JRDX6CUC/The encoding of logical notions in C.pdf;/home/lazylambda/Zotero/storage/K4MF6NUJ/Second order typed lambda calculus.pdf;/home/lazylambda/Zotero/storage/LVJEN2WW/An elaborated example.pdf;/home/lazylambda/Zotero/storage/MTU66YGQ/The Calculus of Constructions.pdf;/home/lazylambda/Zotero/storage/PIHDHIJD/Rules and properties of D.pdf;/home/lazylambda/Zotero/storage/RMP9QVQX/Mathematics in D a first attempt.pdf;/home/lazylambda/Zotero/storage/RULM3ISI/Flag-style natural deduction in D.pdf;/home/lazylambda/Zotero/storage/RXZ8A435/Sets and subsets.pdf;/home/lazylambda/Zotero/storage/Y9JFWFPW/Untyped lambda calculus.pdf}
}

@article{OptimizationProblem2022,
  title = {Optimization Problem},
  year = {2022},
  month = nov,
  journal = {Wikipedia},
  urldate = {2023-08-19},
  abstract = {In mathematics, computer science and economics, an optimization problem is the problem of finding the best solution from all feasible solutions. Optimization problems can be divided into two categories, depending on whether the variables are continuous or discrete:  An optimization problem with discrete variables is known as a discrete optimization, in which an object such as an integer, permutation or graph must be found from a countable set. A problem with continuous variables is known as a continuous optimization, in which an optimal value from a continuous function must be found. They can include constrained problems and multimodal problems.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1119690919},
  file = {/home/lazylambda/Zotero/storage/F9VSZSLD/Optimization_problem.html}
}

@book{pierceTypesProgrammingLanguages2002,
  title = {Types and Programming Languages},
  author = {Pierce, Benjamin C.},
  year = {2002},
  publisher = {{MIT Press}},
  address = {{Cambridge, Mass}},
  isbn = {978-0-262-16209-8},
  langid = {english},
  lccn = {QA76.7 .P54 2002},
  keywords = {Programming languages (Electronic computers)},
  file = {/home/lazylambda/Zotero/storage/UR6HNYNP/Pierce - 2002 - Types and programming languages.pdf}
}
