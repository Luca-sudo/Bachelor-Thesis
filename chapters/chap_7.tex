\chapter{Introducing Lists}

In this chapter we introduce lists as a data type. As we will see, this necessitates various new definitions; The most salient being potentials. Previously, we attached resource-annotations to a type, which resulted in a "What-you-see-is-what-you-get" resource cost. For lists' we need to adapt, instead of a constant cost for any input list, we assign a cost to every list element. This results in resource-consumption respecting the variable length of lists. The notion of potentials will be a key concept in enabling this. Beyond lists, we introduce function application, which introduces recursion into our programming language. 

\begin{definition}[list-tick language]
   \label{def:prog-lang-6}

\begin{align*}
   e := ~~~ & \letexp{x}{e_1}{e_2}		& \text{(let)}\\
            & \tick{k}				& \text{(tick)}\\
	    & x					& \text{(var)}\\
	    & \true ~~| ~~\false		& \text{(bool constructors)}\\
	    & q					& \text{(const integer)}\\
            & \cons{x}{xs} ~~| ~~ \listnil      & \text{(list constructor)}\\
            & \listmatch{l}{e_1}{e_2}           & \text{(match list)}\\
            & \func~f~x = e_f                   & \text{(function abstraction)}\\
            & f x                               & \text{(function application)}\\
\end{align*}
\end{definition}
\todo{Do I have to add function abstraction here?}

Because a list can contain \emph{any type} of data, assuming it is homogenous data, we introduce generic lists. Similarly, we need to introduce function types, which map values of one type to values of another type. For more concrete examples of list types and function types, we supplement examples below.

\begin{definition}[Type system]\label{def:type-system-6}
   \[
      A, B := \unit~|~\text{\bool}~|~\text{\typeint}~|~\ralist{}{A}~|~\rafunc{A}{B}{}{}
   \]
\end{definition}

\begin{example}
   \(\ralist{}{\typeint}\) is the type of lists that contain integers
\end{example}

\begin{example}
   \(\ralist{}{\ralist{}{\bool}}\) is the type of lists that contain lists with values of type \bool.
\end{example}

\begin{example}
   A function \(f(x) = x+1\) has the type \(f :: \rafunc{\typeint}{\typeint}{}{}\).
\end{example}
\todo{Introduce lambda expression in preliminaries}

\begin{example}
   A function \(sum\), that sums integers in a list has the type \(\rafunc{\ralist{}{\typeint}}{\typeint}{}{}\).
\end{example}

We want to infer resource-bounds for programs. In order for the inference to be computationally tractable, we constrain the use of certain language features. Most notably, we enforce that functions on lists only recur on the tail of the list. As a result, recursive function calls \emph{will terminate}, eventually.

While this reduces the set of programs that we permit, most problems on lists naturally have a form that matches this constraint. For example, folding operations such as sum (\cref{fig:code-sum}), or functorial operations such as map (\cref{fig:code-map}), can be defined in this way. 
\todo{@AP Should I elaborate more on this constraint?}

\section{Evaluation Semantics}

We introduce evaluation rules, which are nuanced when we evaluate a list, because the resource demand will, in most cases, be related to the length of the list. This necessitates the introduction of resource demands as \emph{recurrence relations}. We start by introducing recurrence relations and motivate the connection to resource demands. 

\subsection{Recurrence Relations As Resource Demands}

Since we introduced lists and recursion into our programming language, this has a profound impact on the relation between input and resource demands. Previously the values of any type in our type system had no \emph{structural implication} for resource demands. As lists can inhabit any (finite) length, we need to find a general approach to relating lists with resource demands. 

Let us build an intuition for the interplay of resource demands and lists of variable length, by informally working through an example function. For this consider the function \(add1\) in \cref{code:add1}, which increments every entry in the list.

Given a non-empty list \(l\), we execute the body of the second match condition. There, we tick and increment the head of the list. Afterward we call the function recursively on the tail. Thus, we have paid \(2\) resources for the head of the list, plus, the cost of calling the function on the tail, which is not yet determined.

We can model this cost as a function of the list. However, as we do not know how to handle an empty list yet, this is only a partial definition.

\[
   Q(l) = \begin{cases*}
      2 + Q(xs)            & if l = x :: xs\\
      \textbf{undefined}   & else
   \end{cases*}
\]

This aligns with our intuition, as this recurrence relation states that for any list element we have a resource cost of \(2\). To derive a complete recurrence relation, and thus a resource demand for arbitrary, finite lists, we need to understand what cost we assign to the empty list. In our example, we simply return nil with no associated cost. Thus, there is a cost of \(0\) for the empty list. Augmenting the recurrence relation yields the following:

\[
   Q(l) = \begin{cases*}
      2 + Q(xs)            & if l = x :: xs\\
      0                    & else
   \end{cases*}
\]

Which captures the resource demand for arbitrary lists. Having exercised this example, we now define recurrence relations. Notably, we constrain recurrence relations to have \emph{order} 1, as we only allow recursion on the tail of a list. For arbitrary, inductive data types, an order of 1 might not suffice. Binary trees, for example, may require order 2.

\begin{definition}[Recurrence Relation]\label{def:recurrence-relation}
   A \emph{recurrence relation} (of order 1) is an equation that defines the value of each element as a function of the preceding element.
\end{definition}

\subsection{Evaluation Rules}

We start by introducing two rules for the construction of lists, corresponding to the two constructors of our programming language. In this thesis, construction of both empty and non-empty lists has no associated cost. As a result the cost of operations on lists is purely dictated by the actions performed on the list. 

\[
   \inference[(E:Nil)]
   {}
   {\evals{E}{\listnil}{null}{}{}}
   \qquad
   \inference[(E:Cons)]
   {\contains{E}{x, xs} \qquad l = (E(x), E(xs))}
   {\evals{E}{\cons{x}{xs}}{l}{}{}}
\]
\todo{Need to introduce null somewhere}

In order to implement functions that work recursively on a list, we need pattern matching on lists. Whenever a match statement involving a list is invoked, there are two cases: (1) The list passed to it is nil. (2) The list passed to it contains values. The cost of both cases will be combined, to define a recurrence relation (see \cref{def:recurrence-relation}). We first define an evalution rule for matching on empty lists.

\[
   \inference[(E:MatchNil)]
   {E(l) = Null \qquad \evals{E}{e_1}{v}{q_0}{q_1}}
   {\evals{E}{\listmatch{l}{e_1}{e_2}}{v}{q_0}{q_1}}
\]

Next, we define an evaluation rule for non-empty lists. Here, we need to extract all required resource demands, in order to construct a recurrence relation. As a result, we compute the resource demand of empty and non-empty lists, which allows us to create the needed recurrence relation.

\[
   \inference[(E:MatchCons)]
   {E(l) = (v_x, v_{xs}) \qquad \evals{\envaugment{E}{l}{(v_x, v_{xs})}}{e_2}{v}{q(l)}{q'(l)} \qquad \evals{E}{e_1}{v_1}{q_0}{q_1}}
   {\evals{E}{\listmatch{l}{e_1}{e_2}}{v}{Q(l)}{Q'(l)}}
\]
\[
   \begin{aligned}
      \text{where }  & Q(l) \begin{cases*}
         q(x :: xs)     & if l = x :: xs\\
         q_0            & if l = null
         \end{cases*} \text{and } Q'(l) \begin{cases*}
         q'(x :: xs)     & if l = x :: xs\\
         q_1            & if l = null
      \end{cases*}
   \end{aligned}
\]

For the latter rule we define the concrete value of the list \(l\) as a tuple \((v_x, v_{xs})\). Where \(v_x\) is the value contained in the head of the list, and \(v_{xs}\) points to the tail. 

To define recursive functions we are currently missing function application. We define \(e_f\) as the body of the function \(f\), and the variable name \(y_f\) as the argument name used in the definition of \(f\). 
\todo{What about functions with multiple arguments?}

\[
   \inference[(E:App)]
   {E(f) = e_f \qquad \evals{\envaugment{E}{y_f}{x}}{e_f}{v}{q_0}{q_1}}
   {\evals{E}{f x}{v}{q_0}{q_1}}
\]
\todo{Need to define how we get from f to the expression of f}
\todo{Maybe talk about free and bound variables in preface?}

\section{Type Rules}

Our goal is to introduce type rules that allow us to assign resource costs to lists. Previously, we assigned a resource-pair (\cref{def:resource-pair}) to the resulting type; This is not feasible for lists, as the cost of evaluating an expression featuring a list depends on the length of the list. For this, we introduced recurrence relations to model resource demands that respect the length of a list. The type rule analogue to recurrence relations are \emph{potentials}. Intuitively, we assign a potential to a list, which corresponds to a cost for each list element. Having introduced potentials, we will define resource-aware lists, which forces us to consider how potentials can be composed and shared.

\subsection{Resource-Aware Lists}\label{sec:resource-aware-lists}

We start by defining the type of resource-aware lists, the potential function, notation for the length of a list and deriving potential for lists with base types. For this, we start by defining resource-aware lists:

\begin{definition}[Resource-aware list]\label{def:ra-list}
   Let \(p \in \mathbb{N}\), and let \(A\) be a type from \cref{def:type-system-6}. A resource-aware list type is a pair comprising the \emph{base type} and \emph{potential}:

   \[
      \ralist{p}{A} = (\ralist{}{A}, p)
   \]
\end{definition}
\todo{Cref references definition as theorem}

In order to calculate resource bounds using the potential assigned to a list, we need to introduce a potential function. This will be the mathematical foundation for deriving resource bounds that respect the size of the list. 

\begin{definition}[Potential Function]\label{def:potential-function}
   For a value \(v\) of type \(A\), we define the potential of that value as follows:
   \[
      \Phi(v : A) \begin{cases}
         0                                            & A \in \{\unit, \typeint, \bool\}\\
         \Phi(x : B) + \Phi(xs : \ralist{q}{B}) + q   & A = \ralist{q}{B}
      \end{cases}
   \]
\end{definition}

\begin{definition}[Length of lists]\label{def:list-length}
   Given a list \(l : \ralist{}{A}\), we denote by \(|l|\) the \emph{length} of the list.
\end{definition}

The following corollary proves that, for lists that are not nested, the resulting potential of a list is \emph{only} dependent on the length of the list and the potential assigned to it.

\begin{corollary}[Potential of lists]\label{cor:potential-list}
   Let \(l : \ralist{q}{A}\), where \(A \in \{\unit, \typeint, \bool\}\). 
   \[
      \Phi(l : \ralist{q}{A}) = q \cdot |l|
   \]
\end{corollary}
\todo{Need to proof?}

Our definition of the potential function is even more flexible - we are able to derive a potential for \emph{nested lists}. This demonstrates that multivariate resource analysis is possible with our constructions.

\begin{corollary}[Potential of nested list]\label{cor:potential-nested-list}
   Let \(A \in \{\unit, \typeint, \bool\}\), and \(l_i\) be the lists nested inside \(l\). Then:
   \[
      \Phi(l : \ralist{p}{\ralist{q}{A}}) = |l| \cdot p + \sum_{l_i \in l} |l_i| \cdot q
   \]
\end{corollary}

We have defined potentials for all types \(A \in \type\). This allows us to reason about the potential of a \emph{context}; Which is the summed potentials of every variable contained in it. The potential of contexts will be central to our proof of soundness in \cref{sec:soundness-6}.

\section{Inference Rules}

We start by introducing two rules associated to the two list constructors. An empty list can be constructed freely, with no constraints on its potential. On the other hand, constructing a list from an element and another, compatible, list requires us to propagate the potential. The tail \(xs\) of the list is assumed to have potential \(p\), as result, the list \(\cons{x}{xs}\) also has potential \(p\). 

\[
   \inference[(T:Nil)]
   {}
   {\typing{\Gamma}{nil}{\ralist{p}{A}}}
   \qquad
   \inference[(T:Cons)]
   {}
   {\typing{\Gamma;x : A; xs : \ralist{p}{A}}{cons(x, xs)}{\ralist{p}{A}}}
\]

In order to type expression that pattern match on lists, we introduce a rule (T:MatchList). There are a couple of nuances that we want to explain further. Firstly, the return type of both expressions is assumed to be the same. If we want to have a return type that may be distinct for both respective cases, this would require dependent types. 

The potential \(p\) of the list \(l\), which is matched on, is defined as the initial resource cost specific to destructuring the list into head and tail. The expression \(e_1\) has a resource demand of \((q_0, q_1)\), whereas the evaluation of \(e_2\) has a resource demand of \((q_0 + p, q_1)\). Thus, the initial cost for an element of the list is precisely \(p\).  
\todo{Motivate the rule a bit}

\[
   \inference[(T:MatchList)]
   {\typing{\Gamma}{e_1}{\ratype{B}{q_0}{q_1}} \qquad \typing{\Gamma;x : A; xs : \ralist{p}{A}}{e_2}{\ratype{B}{q_0 + p}{q_1}}}
   {\typing{\Gamma;l : \ralist{p}{A}}{\listmatch{l}{e_1}{e_2}}{\ratype{B}{q_0}{q_1}}}
\]

Next, we introduce an inference rule for function application. First, the input type of the function \(f\) needs to align with the variables that are applied. Furthermore, the resource demands of the input variables, as well as the resource demand of the function, need to be propagated - this is similar to propagating values for let expression. 
\todo{Rephrase with currying in mind. Is now introduced}

\[
   \inference[(T:Application)]
   {\typing{\Gamma}{f}{A \to \ratype{B}{q_0}{q_1}}}
   {\typing{\Gamma;x_1:\ratype{A}{p_0}{p_1}}{f x}{\ratype{B}{r_0}{r_1}}}
   \qquad
   \begin{aligned}
      \text{where }  & (r_0, r_1) = (p_0, p_1) \sequence (q_0, q_1)
   \end{aligned}
\]

The rule (T:Application) allows us to type recursive functions. Most importantly, the type of \(x\) and the input type of \(f\) are then inferred to be the same. For recursive calls on a list, we assume that they recur only on the tail \(xs\). Then, the tail has a potential annotation, which is propagated to the function signature, as we assume that the types match. This will be important in the coming examples, as this allows us to type recursive functions.

\subsection{Example Type Derivations}\label{sec:example-type-derivations}

We introduce examples of varying complexity, to illustrate the nuances of type derivation for functions and lists. 

\begin{example}
   For our first example, consider a function \(add1\) that increments every integer in a list. The code can be found in \cref{fig:code-add1}. We derive a resource-annotated type stepwise, for sake of illustration. For this, we write \(e_1\) as an abbreviation for the body of the \(\cons{x}{xs}\) match. 

   Application of (T:MatchList) yields two premises. We close the first premise by applying (T:Nil).

\[
   \inference[(T:MatchList)]
      {
         \inference[(T:Nil)]
         {
         }
         {
            \typing{\Gamma}{l}{\ralist{p}{A}}
         }
         \quad
         \typingHighlight{\typing{\Gamma;x:A;xs:\ralist{p}{A}}{e_1}{\ratype{B}{p_0}{p_1}}}
      }
      {
         \typing{\Gamma;l : \ralist{p}{A}}{\listmatch{l}{\listnil}{e_1}}{B}
      }
\]

Applying (T:Let) splits \(e_1\) up into a tick expression plus the remaining expression, abbreviated \(e_2\). Applying (T:Tick) closes the left branch of the derivation.

\[
   \inference[(T:Let)]
   {
      \inference[(T:Tick)]
      {
      }
      {
         \typing{\Gamma}{\tick{1}}{\ratype{\unit}{1}{0}}
      }
      \quad
      \typingHighlight{\typing{\Gamma;x:A;xs:\ralist{p}{A}}{e_2}{\ratype{B}{q_0}{q_1}}}
   }
   {
      \typing{\Gamma;x:A;xs:\ralist{p}{A}}{\letexp{\_}{\tick{1}}{e_2}}{\ratype{B}{p_0}{p_1}}
   }
\]
\begin{align*}
   \constraintHighlight{\text{where } (p_0, p_1) = (1, 0) \sequence (q_0, q_1)}
\end{align*}

Again, we apply (T:Let), yielding \(x + 1\) and the sub-expression \(e_3\). Applying the rule (T:Op), we infer that \(x : \typeint\). Thus, \(xs : \ralist{p}{\typeint}\) as well.

\[
   \inference[(T:Let)]
   {
      \inference[(T:Op)]
      {
      }
      {
         \typing{\Gamma;x:\typeint}{x + 1}{\typeint}
      }
      \quad
      \typingHighlight{\typing{\Gamma;x':\typeint;xs:\ralist{p}{\typeint}}{e_3}{\ratype{B}{q_0}{q_1}}}
   }
   {
      \typing{\Gamma;x:A;xs:\ralist{p}{A}}{\letexp{x'}{x + 1}{e_3}}{\ratype{B}{q_0}{q_1}}
   }
\]

The final application of (T:Let) generates two premises. The first being the recursive function call on \(xs\), and the second being the construction of the final list. We infer that \(B = \ralist{q}{\typeint}\), resulting from the application of (T:Cons), from which the return type is propagated. 

Furthermore, \(q_0 = 0 = q_1\), as neither sub-expressions have any resource demand.

\[
   \hspace*{-2cm}
   \inference[(T:Let)]
   {
      \typingHighlight{\typing{\Gamma;xs:\ralist{p}{\typeint}}{add1~xs}{\ralist{q}{\typeint}}}
      \inference[(T:Cons)]
      {}
      {
         \typing{\Gamma;x':\typeint;xs':\ralist{q}{\typeint}}{\cons{x'}{xs'}}{\ralist{q}{\typeint}}
      }
   }
   {
      \typing{\Gamma;x':\typeint;xs:\ralist{p}{\typeint}}{\letexp{xs'}{add1~xs}{\cons{x'}{xs'}}}{\ralist{q}{\typeint}}
   }
\]
\begin{align*}
   \constraintHighlight{\text{where } (q_0, q_1) = (0, 0)}
\end{align*}

As a last step, we need to type the recursive function call. The rule (T:Application) allows us to do that. Throughout the previous steps, we derived that the input has type \(\ralist{p}{\typeint}\) and the return type is \(\ralist{q}{\typeint}\). 

\[
   \inference[(T:Application)]
   {
      \typing{\Gamma}{add1}{\ralist{p}{\typeint} \to \ralist{q}{\typeint}}
   }
   {
      \typing{\Gamma;xs:\ralist{p}{\typeint}}{add1~xs}{\ralist{q}{\typeint}}
   }
\]

This concludes the type derivation. Next, we need to collect all constraints and infer optimal values for the potentials of input and output, \(p\) and \(q\) respectively. For this, we need the resource demand of \(e_1\), which we get by combining the constraints highlighted in green. 

\[
   (p_0, p_1) = (1, 0) \implies p = 1
\]

The resulting resource-aware type for \(add1\) is, therefore:

\[
   add1 :: \rafunc{\ralist{1}{\typeint}}{\ralist{}{\typeint}}{}{}
\]
\end{example}

\begin{example}
   For our second example, we define a function \(sum\), which sums all the integers in a list, given an accumulator. The function is defined in \cref{fig:code-sum}.

The associated type derivation can be found in \cref{fig:type-derivation-sum}. Interestingly, this derivation and the previous one are structurally similar: First we pattern match on a list, followed by a let expression. For this reason, the highlights from the previous example can be applied to this example as well.

\begin{figure}[H]
\begin{center}
   \[
      \hspace*{-1.5cm}
      \inference
      {
         \typing{\Gamma}{\listnil}{\ralist{p}{A}}
         &
         \inference
         {
            \typing{}{\tick{3}}{\ratype{\unit}{3}{0}}
            &
            \inference
            {
               \typing{\Gamma}{sum}{\ralist{p}{\typeint} \to \typeint \to \typeint}
            }
            {
               \typing
               {\Gamma;x:\typeint;xs:\ralist{p}{\typeint};n:\typeint}
               {sum~xs~(x+n)}
               {\typeint}
            }
         }
         {
            \typing
            {\Gamma;x:A;xs:\ralist{p}{A};n:B}
            {\letexp{\_}{\tick{3}}{sum~xs~(x+n)}}
            {\ratype{\typeint}{3}{0}}
         }
      }
      {
         \typing
         {\Gamma;l:\ralist{3}{\typeint};n:\typeint}
         {\listmatch{l}{\listnil}{\letexp{\_}{\tick{3}}{sum~xs~(x+n)}}}
         {\typeint}
      }
   \]
   \end{center}
   \caption{Type derivation of the sum function.}
   \label{fig:type-derivation-sum}
\end{figure}

This results in a resource-aware type of the following form:
\[
   sum :: \rafunc{\rafunc{\ralist{3}{\typeint}}{\typeint}{}{}}{\typeint}{}{}
\]
\end{example}

\begin{example}
   Next, we derive a type for the function \(map\) (see \cref{fig:code-map}). In contrast to the previous examples, this is a \emph{higher-order} function. As we will see, the resource demand of the function will depend on two factors: (1) The resource demand of the function passed to map, and (2) the length of the list to map over.

   \begin{figure}[H]
      \[
         \inference
         {
            \inference
            {
               \inference
               {
                  \typing{\Gamma;xs:\ralist{p}{A}}{map~f~xs}{\ralist{q}{B}}
                  &
                  \typing{\Gamma;x':\ratype{B}{q_0}{q_1};xs':\ralist{q}{B}}{\cons{x'}{xs'}}{\ratype{\ralist{q}{B}}{q_0}{q_1}}
               }
               {
                  \typing{\Gamma;x':\ratype{B}{q_0}{q_1};xs:\ralist{p}{A}}{e_{map}'}{\ralist{q}{B}}
               }
               &
               \typing{\Gamma;x:A;f:\rafunc{A}{B}{q_0}{q_1}}{f~x}{\ratype{B}{q_0}{q_1}}
            }
            {
               \typing{\Gamma;f:\rafunc{A}{B}{q_0}{q_1};l:\ralist{p}{A}}{e_{map}}{\ralist{q}{B}}
            }
            &
            \typing{\Gamma}{\listnil}{\ralist{p}{A}}
         }
         {
            \typing{\Gamma;f:\rafunc{A}{B}{q_0}{q_1};l:\ralist{p}{A}}{map~f~l}{\ralist{q}{B}}
         }
      \]
   \caption{Type derivation for the function \(fold\).}
   \label{fig:derivation-fold}
   \end{figure}
   \todo{Make type derivation pretty}

Solving the list of constraints, we get that \(p = q_0 - q_1\). We can interpret this result as follows: For every element in the list, the required resources are precisely the resource consumption of the function \(f\) that is applied to the list element. As a result, the resource demand of the function \(map\) is solely determined by the function \(f\) that we pass.

Thus, the resource-annotated signature is:
\[
   map :: (\rafunc{A}{B}{q_0}{q_1}) \to \ralist{(q_0 - q_1)}{A} \to \ralist{}{B}
\]

\end{example}

\begin{remark}
   We assumed that the function \(f\) has resource demand \((q_0, q_1)\). Thus, the above typing \emph{does not} offer a general resource-aware typing for any function.
\end{remark}

\section{Soundness}\label{sec:soundness-6}

The introduction of potentials has a profound effect on the proof of soundness. Previously, the proof centered around inequalities on resource demands - this does not suffice. The \emph{effective cost} that is modelled by type inference is composed of resource demands and the potential of the context. This matches the notion of amortized cost, as introduced in \dots
\todo{Ref to preliminaries talking about amortized cost}

This forces us to embellish the inequalities required to hold for soundness. Consider that evaluation and typing judgements have the following form:  \(\evals{E}{e}{v}{p_0}{p_1}\) and \(\typing{\Gamma}{e}{\ratype{A}{q_0}{q_1}}\). In order to define sound resource inequalities which account for potentials, we reconsider initial and residual resources. The amortized \emph{initial} cost of an operation is composed of the concrete initial resources \emph{and} the potential of the context in which the operation is performed. Thus the initial resources are given by \(p_0 + \Phi(\Gamma)\). 

In the case of residual resources, a similar line of thought holds. Here, we additionally account for the potential of the returned value \(v\), which yields \(q_1 + \Phi(v : A)\). With both initial and residual resources defined, we express soundness as a relaxation \((q_0 + \Phi(\Gamma), q_1 + \Phi(v : A)) \relaxation (p_0, p_1)\), yielding two inequalities \(q_0 + \Phi(\Gamma) \geq p_0\) and \((q_0 - q_1) + (\Phi(\Gamma) - \Phi(v : A)) \geq p_0 - p_1\).



\begin{theorem}[Soundness of typing for var-tick language]\label{thm:soundness-5}
   Let \(E\) be an \nameref{def:environment}, \(\Gamma\) be a \nameref{def:context}. Further, let \(A \in \type\), \((p_0, p_1), (q_0, q_1) \in \demand\) and an expression \(e\) that evaluates to the value \(v\). 

   \begin{center}
   If \(\evals{E}{e}{v}{p_0}{p_1}\) and \(\typing{\Gamma}{e}{\ratype{A}{q_0}{q_1}}\), then \(v : \ratype{A}{}{}\) with \((q_0 + \Phi(\Gamma), q_1 + \Phi(v : A)) \relaxation (p_0, p_1)\).
   \end{center}
\end{theorem}

\begin{proof}
\end{proof}
 
\section{Questions}

