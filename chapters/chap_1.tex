\chapter{Preliminaries} \label{chap:linear}

\section{Amortized Analysis: Potential Method}
Analysing the time and space complexity of algorithms is itself a vast field. For AARA, amortized analysis using the potential method is used. To perform amortized analysis, we define a potential function \(\Phi\), which assigns to every possible state of a data structure a \emph{non-negative} integer. Using the potential assigned to a specific state, more expensive operations can be amortized by preceding, cheaper operations.

To illustrate the advantage of amortized analysis over worst-case analysis, we illustrate both using sequences of inserts over a \emph{DynamicArray} as an example. When initialising a DynamicArray, we provide the size needed. Subsequent inserts to the DynamicArray will be performed instantaneously if memory is free. Whenever an insert to the array would exceed the memory allocated to it, the array doubles in size.
This operation is costly, because we have to allocate the memory and move all previous data into the new memory location. Looking at the worst-case runtime, inserting into a dynamic array has a cost of \(\mathcal{O}(n)\). There are two important nuances: (1) Not every insert operation is equally costly and (2) The expensive inserts are rarer.

In order to perform amortized analysis using the potential method, we first need to define a potential function \(\Phi\). The amortized cost is subsequently given as the sum of the actual cost of the operation and the difference in potential before and after the operation. Formally, we write \(C_{actual}(o)\) to denote the actual cost of some operation \(o\) as well as \(S_{before}\) and \(S_{after}\) for the state of the DynamicArray before and after performing operation \(o\). This yields the following formula for the amortized cost of an operation \(o\):

\[C_{amortized}(o) = C_{actual}(o) + (\Phi(S_{after}) - \Phi(S_{before}))\]
\label{eq:amortized-cost}

For an arbitrary DynamicArray \(D\) of size \(N\), of which \(n\) memory cells have been used,  we define the potential function \(\Phi(D) = 2n - N\). Note that \(n \leq N\) and \(2n \geq N\), because the DynamicArray is always at least half full due to the resizing strategy explained above. 
As alluded to earlier, a potential function needs to be non-negative for every possible state passed to it. We can immediately conclude that the above function satisfies that constraint, due to \(2n \geq N\) being an invariant. We now examine how different types of insert operations affect the potential function and subsequently the amortized cost.
Suppose we insert into a DynamicArray, such that no doubling in size is necessary. The actual cost of the operation is constant. Because no resizing of the DynamicArray is induced, we simply increment \(n\). This yields the following potentials:

\[\Phi(S_{before}) = 2n - N\]
\[\Phi(S_{after}) = 2(n + 1) - N\]
\todo{Label/annotate equations?}

Hence, \(\Phi(S_{after}) - \Phi(S_{before}) = 2\). This yields an amortized cost of \(C_{amortized}(o) = C_{actual}(o) + 2\), where we know that \(C_{actual}(o)\) is constant. As a result, the amortized cost is again constant.

Let us now assume that we insert one element into a DynamicArray, inducing a doubling in size. This results in the following potentials:

\[\Phi(S_{before}) = 2n - N\]
\[\Phi(S_{after}) = 2(n + 1) - 2N\]

Note that \(n + 1 = N\), because the array needed to double in size. The potential therefore simplifies to \(\Phi(S_{after}) = 0\). This concludes that our potential function is indeed well-formed, because it will not yield negative values for any valid state.
We know that the actual cost of resizing the array is \(\mathcal{O}(n)\), pluging this into the formula for amortized cost: \(C_{amortized}(o) = \mathcal{O}(n) + ( 0 - \mathcal{O}(n))\). Yielding constant time again, because the difference in potential allowed us to 'pay' for the cost incurred by reallocating the array.

Generalizing the new won insight, allows us to claim the following: \emph{Any sequence of n insert operations takes \(\mathcal{O}(n)\) amortized time}. This follows, as the sum of \(n\) constant time operations is \(\mathcal{O}(n)\). 

The formula for amortized cost \ref{eq:amortized-cost} allows us to provide an upper bound on the actual cost of an operation as well. Since the potential function is required to be non-negative, we get that \(\Phi(S) \geq 0\) for some state \(S\). Using this inequality, we can infer the following bound simply by using the new inequality:

\[C_{actual}(o) \leq C_{amortized}(o)\]
\label{ineq:actual-amortized}

Because we inferred that any sequence of \(n\) insert operations has \(\mathcal{O}(n)\) amortized cost, this inequality shows that any sequence of insert operations also has at most \(\mathcal{O}(n)\) actual cost.

AARA will deploy the potential method in order to provide bounds. To this end, we will define properties of the potential function in \ref{chap:potential-properties}.
\todo{Reference to chapter for potential properties.}

\section{Type System}

A type system groups values in a computer program into different \emph{types} and defines the set of operations that are valid on each type. Most programmers were already exposed to types, some of them being: string, integers, floats. Subsequently, the operations defined on those types may differ; where we might be able to multiply two integers, it is not immediately clear what multiplying two strings means.
Multiplying two integers yields again an integer, this behavior is encoded into type rules which comprise a set of premises, assertions that must hold prior, and a set of conclusions, which hold if all the premises are fullfilled. As such, we may encode the fact that multiplying two integers yields again an integer into a type rule.
Leveraging the type system and type rules will allow automatic resource analysis as presented in \ref{chap:linear-potential}.




